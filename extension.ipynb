{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "\n",
    "# Build an English pipeline\n",
    "#stanza.download('en', package='mimic', processors={'ner': 'i2b2'}) # download English model\n",
    "#nlp = stanza.Pipeline('en', package='mimic', processors={'ner': 'i2b2'}) # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.read_csv('/home/chudeo/coding-evidence-extraction-main/work_sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She continued to slowly progress and her menta...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "      <td>PRON,VERB,PART,ADV,VERB,CCONJ,PRON,ADJ,NOUN,AD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discharge Disposition : Expired</td>\n",
       "      <td>O,O,O,O</td>\n",
       "      <td>PROPN,NOUN,PUNCT,PROPN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amt : 270 ********************************* CP...</td>\n",
       "      <td>O,O,O,O,O,O,O,O</td>\n",
       "      <td>NOUN,PUNCT,NUM,PUNCT,PUNCT,PUNCT,PUNCT,PUNCT,P...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMPARISON : Preoperative studies , most recen...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "      <td>NOUN,PUNCT,ADJ,NOUN,PUNCT,ADV,ADV,VERB,PUNCT,P...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is no free fluid or free air in the abdo...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "      <td>PRON,VERB,DET,ADJ,NOUN,CCONJ,ADJ,NOUN,ADP,DET,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  She continued to slowly progress and her menta...   \n",
       "1                    Discharge Disposition : Expired   \n",
       "2  Amt : 270 ********************************* CP...   \n",
       "3  COMPARISON : Preoperative studies , most recen...   \n",
       "4  There is no free fluid or free air in the abdo...   \n",
       "\n",
       "                                   word_labels  \\\n",
       "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O   \n",
       "1                                      O,O,O,O   \n",
       "2                              O,O,O,O,O,O,O,O   \n",
       "3                  O,O,O,O,O,O,O,O,O,O,O,O,O,O   \n",
       "4                      O,O,O,O,O,O,O,O,O,O,O,O   \n",
       "\n",
       "                                            pos_tags  sentence_id  \n",
       "0  PRON,VERB,PART,ADV,VERB,CCONJ,PRON,ADJ,NOUN,AD...            1  \n",
       "1                             PROPN,NOUN,PUNCT,PROPN            2  \n",
       "2  NOUN,PUNCT,NUM,PUNCT,PUNCT,PUNCT,PUNCT,PUNCT,P...            3  \n",
       "3  NOUN,PUNCT,ADJ,NOUN,PUNCT,ADV,ADV,VERB,PUNCT,P...            4  \n",
       "4  PRON,VERB,DET,ADJ,NOUN,CCONJ,ADJ,NOUN,ADP,DET,...            5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence       4378\n",
       "word_labels    4378\n",
       "pos_tags       4378\n",
       "sentence_id    4378\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence       0\n",
       "word_labels    0\n",
       "pos_tags       0\n",
       "sentence_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "token_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = token_df.drop(columns=['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 13:02:23.480740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 13:02:26.017075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words, labels, and POS tags from DataFrame\n",
    "split_data = {\n",
    "    \"sentence\": [word for sent in data[\"sentence\"].str.split() for word in sent],\n",
    "    \"word_labels\": [label.split(',') for label in data[\"word_labels\"]],\n",
    "    \"pos_tags\": [pos.split(',') for pos in data[\"pos_tags\"]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into sentences and labels\n",
    "sentences = split_data[\"sentence\"]\n",
    "labels = split_data[\"word_labels\"]\n",
    "pos = split_data[\"pos_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\")\n",
    "tokenized_sentences = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes\n",
    "tag2idx = {\"O\": 0, \"B\": 1, \"I\": 2}\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "num_classes = len(tag2idx)\n",
    "MAX_LEN= 128\n",
    "TRAIN_BATCH_SIZE =16\n",
    "VALID_BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B': 1, 'I': 2}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract all unique labels from the DataFrame\n",
    "unique_labels = set(','.join(data['word_labels'].values).split(','))\n",
    "\n",
    "# Define the desired label order\n",
    "desired_labels = ['O', 'B', 'I']\n",
    "\n",
    "# Create the label-to-id mapping\n",
    "label2id = {label: idx for idx, label in enumerate(desired_labels)}\n",
    "\n",
    "# Create the id-to-label mapping\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Print the label-to-id mapping\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.data.sentence[index]\n",
    "        word_labels = self.data.word_labels[index]\n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"]\n",
    "        labels.insert(0, \"O\")\n",
    "        labels.insert(-1, \"O\")\n",
    "\n",
    "        if len(tokenized_sentence) > self.max_len:\n",
    "            tokenized_sentence = tokenized_sentence[:self.max_len]\n",
    "            labels = labels[:self.max_len]\n",
    "        else:\n",
    "            tokenized_sentence = tokenized_sentence + ['[PAD]' for _ in range(self.max_len - len(tokenized_sentence))]\n",
    "            labels = labels + [\"O\" for _ in range(self.max_len - len(labels))]\n",
    "\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (4378, 3)\n",
      "TRAIN Dataset: (3502, 3)\n",
      "TEST Dataset: (876, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_data = data.sample(frac=train_size, random_state=200)\n",
    "test_data = data.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "train_dataset = NERDataset(train_data, tokenizer, MAX_LEN)\n",
    "test_dataset = NERDataset(test_data, tokenizer, MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101, 36408,  8745,  1665,  3575,  3773,  1105,   172,  1477, 13408,\n",
       "          3773,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 36408,  8745,  1665,  3575,  3773,  1105,   172,  1477, 13408,\n",
       "         3773,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       O\n",
      "ano         O\n",
      "##xi        O\n",
      "##c         O\n",
      "brain       O\n",
      "injury      O\n",
      "and         O\n",
      "c           B\n",
      "##2         B\n",
      "cord        I\n",
      "injury      I\n",
      ".           O\n",
      "[SEP]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n"
     ]
    }
   ],
   "source": [
    "# print the first 30 tokens and corresponding labels\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(train_dataset[0][\"input_ids\"][:30]), train_dataset[0][\"labels\"][:30]):\n",
    "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define  DataLoader parameters\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE, 'shuffle': True, 'num_workers': 0}\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE, 'shuffle': False, 'num_workers': 0}\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "test_loader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model\n",
    "model = BertForTokenClassification.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\", num_labels=num_classes)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train_dataset[0][\"input_ids\"].unsqueeze(0)\n",
    "mask = train_dataset[0][\"attention_mask\"].unsqueeze(0)\n",
    "targets = train_dataset[0][\"labels\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "\n",
    "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report as seqeval_classification_report\n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            targets = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            active_logits = eval_logits.view(-1, model.num_labels)\n",
    "            active_labels = targets.view(-1)\n",
    "\n",
    "            eval_preds.extend(torch.argmax(active_logits, axis=1).cpu().numpy())\n",
    "            eval_labels.extend(active_labels.cpu().numpy())\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "    labels = [[id2label[id_]] for id_ in eval_labels]\n",
    "    predictions = [[id2label[id_]] for id_ in eval_preds]\n",
    "\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(seqeval_classification_report(labels, predictions))\n",
    "\n",
    "    return labels, predictions\n",
    "\n",
    "labels, predictions = valid(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report as seqeval_classification_report\n",
    "from sklearn.metrics import classification_report as sklearn_classification_report\n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            targets = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            active_logits = eval_logits.view(-1, model.num_labels)\n",
    "            active_labels = targets.view(-1)\n",
    "\n",
    "            eval_preds.extend(torch.argmax(active_logits, axis=1).cpu().numpy())\n",
    "            eval_labels.extend(active_labels.cpu().numpy())\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "    labels = [[id2label[id_]] for id_ in eval_labels]\n",
    "    predictions = [[id2label[id_]] for id_ in eval_preds]\n",
    "\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "\n",
    "    # Get unique labels\n",
    "    unique_labels = set([label for sublist in labels for label in sublist] + [label for sublist in predictions for label in sublist])\n",
    "    unique_labels = sorted(unique_labels)\n",
    "\n",
    "    # Fill in empty lists for missing labels\n",
    "    filled_labels = []\n",
    "    filled_predictions = []\n",
    "    for lbl, pred in zip(labels, predictions):\n",
    "        filled_lbl = lbl + [l for l in unique_labels if l not in lbl]\n",
    "        filled_pred = pred + [l for l in unique_labels if l not in pred]\n",
    "        filled_labels.append(filled_lbl)\n",
    "        filled_predictions.append(filled_pred)\n",
    "\n",
    "    print(\"Classification Report (SeqEval):\")\n",
    "    print(seqeval_classification_report(filled_labels, filled_predictions))\n",
    "\n",
    "    print(\"Classification Report (Sklearn):\")\n",
    "    print(sklearn_classification_report([label[0] for label in filled_labels], [pred[0] for pred in filled_predictions]))\n",
    "\n",
    "    return labels, predictions\n",
    "\n",
    "labels, predictions = valid(model, test_loader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'bert_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predicted labels with corresponding words\n",
    "def get_predicted_evidence(model, dataloader):\n",
    "    all_pred_evidence = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get the predicted labels\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Convert predicted labels to evidence format\n",
    "            for i in range(len(predicted_labels)):\n",
    "                sentence_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
    "                sentence_labels = [id2label[label.item()] for label in predicted_labels[i]]\n",
    "\n",
    "                # Collect evidence for each sentence\n",
    "                sentence_evidence = []\n",
    "                for j, label in enumerate(sentence_labels):\n",
    "                    if label != 'O':\n",
    "                        start = 0\n",
    "                        for k in range(j):\n",
    "                            start += len(tokenizer.tokenize(sentence_tokens[k]))\n",
    "                        end = start + len(tokenizer.tokenize(sentence_tokens[j]))\n",
    "                        sentence_evidence.append({\n",
    "                            'word': sentence_tokens[j],\n",
    "                            'label': label,\n",
    "                            'start': start,\n",
    "                            'end': end\n",
    "                        })\n",
    "                all_pred_evidence.append(sentence_evidence)\n",
    "\n",
    "    return all_pred_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted evidence\n",
    "all_pred_evidence = get_predicted_evidence(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert evidence to DataFrame\n",
    "pred_df = pd.DataFrame({\n",
    "    'Word': [e['word'] for sentence in all_pred_evidence for e in sentence],\n",
    "    'Predicted_Label': [e['label'] for sentence in all_pred_evidence for e in sentence]\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "pred_df.to_csv('predicted_evidence.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Predicted Labels** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_labels(model, dataloader):\n",
    "    all_pred_labels = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Get the predicted labels\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # Convert predicted labels to the required format\n",
    "            batch_pred_labels = []\n",
    "            for i in range(len(predicted_labels)):\n",
    "                sentence_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
    "                sentence_labels = [id2label[label.item()] for label in predicted_labels[i]]\n",
    "                \n",
    "                # Convert the sentence-level predictions to the required format\n",
    "                for j, label in enumerate(sentence_labels):\n",
    "                    if label != 'O':\n",
    "                        start = 0\n",
    "                        for k in range(j):\n",
    "                            start += len(tokenizer.tokenize(sentence_tokens[k]))\n",
    "                        end = start + len(tokenizer.tokenize(sentence_tokens[j]))\n",
    "                        batch_pred_labels.append({\n",
    "                            'label': label,\n",
    "                            'start': start,\n",
    "                            'end': end\n",
    "                        })\n",
    "            all_pred_labels.append(batch_pred_labels)\n",
    "    \n",
    "    return all_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_labels = get_predicted_labels(model, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NERVALUATE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from nervaluate import Evaluator\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv('/home/chudeo/project/33k_sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the true labels\n",
    "all_true_labels = []\n",
    "for _, row in data.iterrows():\n",
    "    sentence = row['words']\n",
    "    word_labels = row['labels'].split(',')\n",
    "    true_labels = []\n",
    "    for i, label in enumerate(word_labels):\n",
    "        if label != 'O':\n",
    "            true_labels.append({\n",
    "                'label': label,\n",
    "                'start': 0,\n",
    "                'end': 0 \n",
    "            })\n",
    "    all_true_labels.append(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted labels from the model\n",
    "all_pred_labels = []\n",
    "for batch in test_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    batch_pred_labels = []\n",
    "    for i in range(len(predicted_labels)):\n",
    "        sentence_tokens = tokenizer.convert_ids_to_tokens(input_ids[i])\n",
    "        sentence_labels = [id2label[label.item()] for label in predicted_labels[i]]\n",
    "\n",
    "        for j, label in enumerate(sentence_labels):\n",
    "            if label != 'O':\n",
    "                start = 0\n",
    "                for k in range(j):\n",
    "                    start += len(tokenizer.tokenize(sentence_tokens[k]))\n",
    "                end = start + len(tokenizer.tokenize(sentence_tokens[j]))\n",
    "                batch_pred_labels.append({\n",
    "                    'label': label,\n",
    "                    'start': start,\n",
    "                    'end': end\n",
    "                })\n",
    "    all_pred_labels.append(batch_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the lengths of all_true_labels and all_pred_labels match\n",
    "if len(all_true_labels) > len(all_pred_labels):\n",
    "    all_pred_labels.extend([[] for _ in range(len(all_true_labels) - len(all_pred_labels))])\n",
    "elif len(all_true_labels) < len(all_pred_labels):\n",
    "    all_true_labels.extend([[] for _ in range(len(all_pred_labels) - len(all_true_labels))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique labels from the true labels\n",
    "unique_labels = set()\n",
    "for true_labels in all_true_labels:\n",
    "    for label_dict in true_labels:\n",
    "        unique_labels.add(label_dict['label'])\n",
    "unique_labels = list(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the unique labels as the tags parameter\n",
    "evaluator = Evaluator(all_true_labels, all_pred_labels, tags=unique_labels)\n",
    "\n",
    "# Returns overall metrics and metrics for each tag\n",
    "results, results_per_tag = evaluator.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_per_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel",
   "language": "python",
   "name": "intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1a69bf678df178a0a83c1bc249e551d0589a35527ff82fba5716df60535a642"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
